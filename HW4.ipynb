{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                          ]       0 / 1475504\r",
      "  0% [                                                                          ]    8192 / 1475504\r",
      "  1% [                                                                          ]   16384 / 1475504\r",
      "  1% [.                                                                         ]   24576 / 1475504\r",
      "  2% [.                                                                         ]   32768 / 1475504\r",
      "  2% [..                                                                        ]   40960 / 1475504\r",
      "  3% [..                                                                        ]   49152 / 1475504\r",
      "  3% [..                                                                        ]   57344 / 1475504\r",
      "  4% [...                                                                       ]   65536 / 1475504\r",
      "  4% [...                                                                       ]   73728 / 1475504\r",
      "  5% [....                                                                      ]   81920 / 1475504\r",
      "  6% [....                                                                      ]   90112 / 1475504\r",
      "  6% [....                                                                      ]   98304 / 1475504\r",
      "  7% [.....                                                                     ]  106496 / 1475504\r",
      "  7% [.....                                                                     ]  114688 / 1475504\r",
      "  8% [......                                                                    ]  122880 / 1475504\r",
      "  8% [......                                                                    ]  131072 / 1475504\r",
      "  9% [......                                                                    ]  139264 / 1475504\r",
      "  9% [.......                                                                   ]  147456 / 1475504\r",
      " 10% [.......                                                                   ]  155648 / 1475504\r",
      " 11% [........                                                                  ]  163840 / 1475504\r",
      " 11% [........                                                                  ]  172032 / 1475504\r",
      " 12% [.........                                                                 ]  180224 / 1475504\r",
      " 12% [.........                                                                 ]  188416 / 1475504\r",
      " 13% [.........                                                                 ]  196608 / 1475504\r",
      " 13% [..........                                                                ]  204800 / 1475504\r",
      " 14% [..........                                                                ]  212992 / 1475504\r",
      " 14% [...........                                                               ]  221184 / 1475504\r",
      " 15% [...........                                                               ]  229376 / 1475504\r",
      " 16% [...........                                                               ]  237568 / 1475504\r",
      " 16% [............                                                              ]  245760 / 1475504\r",
      " 17% [............                                                              ]  253952 / 1475504\r",
      " 17% [.............                                                             ]  262144 / 1475504\r",
      " 18% [.............                                                             ]  270336 / 1475504\r",
      " 18% [.............                                                             ]  278528 / 1475504\r",
      " 19% [..............                                                            ]  286720 / 1475504\r",
      " 19% [..............                                                            ]  294912 / 1475504\r",
      " 20% [...............                                                           ]  303104 / 1475504\r",
      " 21% [...............                                                           ]  311296 / 1475504\r",
      " 21% [................                                                          ]  319488 / 1475504\r",
      " 22% [................                                                          ]  327680 / 1475504\r",
      " 22% [................                                                          ]  335872 / 1475504\r",
      " 23% [.................                                                         ]  344064 / 1475504\r",
      " 23% [.................                                                         ]  352256 / 1475504\r",
      " 24% [..................                                                        ]  360448 / 1475504\r",
      " 24% [..................                                                        ]  368640 / 1475504\r",
      " 25% [..................                                                        ]  376832 / 1475504\r",
      " 26% [...................                                                       ]  385024 / 1475504\r",
      " 26% [...................                                                       ]  393216 / 1475504\r",
      " 27% [....................                                                      ]  401408 / 1475504\r",
      " 27% [....................                                                      ]  409600 / 1475504\r",
      " 28% [....................                                                      ]  417792 / 1475504\r",
      " 28% [.....................                                                     ]  425984 / 1475504\r",
      " 29% [.....................                                                     ]  434176 / 1475504\r",
      " 29% [......................                                                    ]  442368 / 1475504\r",
      " 30% [......................                                                    ]  450560 / 1475504\r",
      " 31% [.......................                                                   ]  458752 / 1475504\r",
      " 31% [.......................                                                   ]  466944 / 1475504\r",
      " 32% [.......................                                                   ]  475136 / 1475504\r",
      " 32% [........................                                                  ]  483328 / 1475504\r",
      " 33% [........................                                                  ]  491520 / 1475504\r",
      " 33% [.........................                                                 ]  499712 / 1475504\r",
      " 34% [.........................                                                 ]  507904 / 1475504\r",
      " 34% [.........................                                                 ]  516096 / 1475504\r",
      " 35% [..........................                                                ]  524288 / 1475504\r",
      " 36% [..........................                                                ]  532480 / 1475504\r",
      " 36% [...........................                                               ]  540672 / 1475504\r",
      " 37% [...........................                                               ]  548864 / 1475504\r",
      " 37% [...........................                                               ]  557056 / 1475504\r",
      " 38% [............................                                              ]  565248 / 1475504\r",
      " 38% [............................                                              ]  573440 / 1475504\r",
      " 39% [.............................                                             ]  581632 / 1475504\r",
      " 39% [.............................                                             ]  589824 / 1475504\r",
      " 40% [.............................                                             ]  598016 / 1475504\r",
      " 41% [..............................                                            ]  606208 / 1475504\r",
      " 41% [..............................                                            ]  614400 / 1475504\r",
      " 42% [...............................                                           ]  622592 / 1475504\r",
      " 42% [...............................                                           ]  630784 / 1475504\r",
      " 43% [................................                                          ]  638976 / 1475504\r",
      " 43% [................................                                          ]  647168 / 1475504\r",
      " 44% [................................                                          ]  655360 / 1475504\r",
      " 44% [.................................                                         ]  663552 / 1475504\r",
      " 45% [.................................                                         ]  671744 / 1475504\r",
      " 46% [..................................                                        ]  679936 / 1475504\r",
      " 46% [..................................                                        ]  688128 / 1475504\r",
      " 47% [..................................                                        ]  696320 / 1475504\r",
      " 47% [...................................                                       ]  704512 / 1475504\r",
      " 48% [...................................                                       ]  712704 / 1475504\r",
      " 48% [....................................                                      ]  720896 / 1475504\r",
      " 49% [....................................                                      ]  729088 / 1475504\r",
      " 49% [....................................                                      ]  737280 / 1475504\r",
      " 50% [.....................................                                     ]  745472 / 1475504\r",
      " 51% [.....................................                                     ]  753664 / 1475504\r",
      " 51% [......................................                                    ]  761856 / 1475504\r",
      " 52% [......................................                                    ]  770048 / 1475504\r",
      " 52% [.......................................                                   ]  778240 / 1475504\r",
      " 53% [.......................................                                   ]  786432 / 1475504\r",
      " 53% [.......................................                                   ]  794624 / 1475504\r",
      " 54% [........................................                                  ]  802816 / 1475504\r",
      " 54% [........................................                                  ]  811008 / 1475504\r",
      " 55% [.........................................                                 ]  819200 / 1475504\r",
      " 56% [.........................................                                 ]  827392 / 1475504\r",
      " 56% [.........................................                                 ]  835584 / 1475504\r",
      " 57% [..........................................                                ]  843776 / 1475504\r",
      " 57% [..........................................                                ]  851968 / 1475504\r",
      " 58% [...........................................                               ]  860160 / 1475504\r",
      " 58% [...........................................                               ]  868352 / 1475504\r",
      " 59% [...........................................                               ]  876544 / 1475504\r",
      " 59% [............................................                              ]  884736 / 1475504\r",
      " 60% [............................................                              ]  892928 / 1475504\r",
      " 61% [.............................................                             ]  901120 / 1475504\r",
      " 61% [.............................................                             ]  909312 / 1475504\r",
      " 62% [..............................................                            ]  917504 / 1475504\r",
      " 62% [..............................................                            ]  925696 / 1475504\r",
      " 63% [..............................................                            ]  933888 / 1475504\r",
      " 63% [...............................................                           ]  942080 / 1475504\r",
      " 64% [...............................................                           ]  950272 / 1475504\r",
      " 64% [................................................                          ]  958464 / 1475504\r",
      " 65% [................................................                          ]  966656 / 1475504\r",
      " 66% [................................................                          ]  974848 / 1475504\r",
      " 66% [.................................................                         ]  983040 / 1475504\r",
      " 67% [.................................................                         ]  991232 / 1475504\r",
      " 67% [..................................................                        ]  999424 / 1475504\r",
      " 68% [..................................................                        ] 1007616 / 1475504\r",
      " 68% [..................................................                        ] 1015808 / 1475504\r",
      " 69% [...................................................                       ] 1024000 / 1475504"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 69% [...................................................                       ] 1032192 / 1475504\r",
      " 70% [....................................................                      ] 1040384 / 1475504\r",
      " 71% [....................................................                      ] 1048576 / 1475504\r",
      " 71% [....................................................                      ] 1056768 / 1475504\r",
      " 72% [.....................................................                     ] 1064960 / 1475504\r",
      " 72% [.....................................................                     ] 1073152 / 1475504\r",
      " 73% [......................................................                    ] 1081344 / 1475504\r",
      " 73% [......................................................                    ] 1089536 / 1475504\r",
      " 74% [.......................................................                   ] 1097728 / 1475504\r",
      " 74% [.......................................................                   ] 1105920 / 1475504\r",
      " 75% [.......................................................                   ] 1114112 / 1475504\r",
      " 76% [........................................................                  ] 1122304 / 1475504\r",
      " 76% [........................................................                  ] 1130496 / 1475504\r",
      " 77% [.........................................................                 ] 1138688 / 1475504\r",
      " 77% [.........................................................                 ] 1146880 / 1475504\r",
      " 78% [.........................................................                 ] 1155072 / 1475504\r",
      " 78% [..........................................................                ] 1163264 / 1475504\r",
      " 79% [..........................................................                ] 1171456 / 1475504\r",
      " 79% [...........................................................               ] 1179648 / 1475504\r",
      " 80% [...........................................................               ] 1187840 / 1475504\r",
      " 81% [...........................................................               ] 1196032 / 1475504\r",
      " 81% [............................................................              ] 1204224 / 1475504\r",
      " 82% [............................................................              ] 1212416 / 1475504\r",
      " 82% [.............................................................             ] 1220608 / 1475504\r",
      " 83% [.............................................................             ] 1228800 / 1475504\r",
      " 83% [..............................................................            ] 1236992 / 1475504\r",
      " 84% [..............................................................            ] 1245184 / 1475504\r",
      " 84% [..............................................................            ] 1253376 / 1475504\r",
      " 85% [...............................................................           ] 1261568 / 1475504\r",
      " 86% [...............................................................           ] 1269760 / 1475504\r",
      " 86% [................................................................          ] 1277952 / 1475504\r",
      " 87% [................................................................          ] 1286144 / 1475504\r",
      " 87% [................................................................          ] 1294336 / 1475504\r",
      " 88% [.................................................................         ] 1302528 / 1475504\r",
      " 88% [.................................................................         ] 1310720 / 1475504\r",
      " 89% [..................................................................        ] 1318912 / 1475504\r",
      " 89% [..................................................................        ] 1327104 / 1475504\r",
      " 90% [..................................................................        ] 1335296 / 1475504\r",
      " 91% [...................................................................       ] 1343488 / 1475504\r",
      " 91% [...................................................................       ] 1351680 / 1475504\r",
      " 92% [....................................................................      ] 1359872 / 1475504\r",
      " 92% [....................................................................      ] 1368064 / 1475504\r",
      " 93% [.....................................................................     ] 1376256 / 1475504\r",
      " 93% [.....................................................................     ] 1384448 / 1475504\r",
      " 94% [.....................................................................     ] 1392640 / 1475504\r",
      " 94% [......................................................................    ] 1400832 / 1475504\r",
      " 95% [......................................................................    ] 1409024 / 1475504\r",
      " 96% [.......................................................................   ] 1417216 / 1475504\r",
      " 96% [.......................................................................   ] 1425408 / 1475504\r",
      " 97% [.......................................................................   ] 1433600 / 1475504\r",
      " 97% [........................................................................  ] 1441792 / 1475504\r",
      " 98% [........................................................................  ] 1449984 / 1475504\r",
      " 98% [......................................................................... ] 1458176 / 1475504\r",
      " 99% [......................................................................... ] 1466368 / 1475504\r",
      " 99% [......................................................................... ] 1474560 / 1475504\r",
      "100% [..........................................................................] 1475504 / 1475504"
     ]
    }
   ],
   "source": [
    "data = wget.download('https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Make', 'Model', 'Year', 'Engine Fuel Type', 'Engine HP',\n",
       "       'Engine Cylinders', 'Transmission Type', 'Driven_Wheels',\n",
       "       'Number of Doors', 'Market Category', 'Vehicle Size', 'Vehicle Style',\n",
       "       'highway MPG', 'city mpg', 'Popularity', 'MSRP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with the MSRP variable, and we'll transform it to a classification task.\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "* Make,\n",
    "* Model,\n",
    "* Year,\n",
    "* Engine HP,\n",
    "* Engine Cylinders,\n",
    "* Transmission Type,\n",
    "* Vehicle Style,\n",
    "* highway MPG,\n",
    "* city mpg\n",
    "* MSRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keep only the columns above\n",
    "* Lowercase the column names and replace spaces with underscores\n",
    "* Fill the missing values with 0\n",
    "* Make the price binary (1 if above the average, 0 otherwise) - this will be our target variable above_average  \n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split function for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine HP</th>\n",
       "      <th>Engine Cylinders</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Vehicle Style</th>\n",
       "      <th>highway MPG</th>\n",
       "      <th>city mpg</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Make       Model  Year  Engine HP  Engine Cylinders Transmission Type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  Vehicle Style  highway MPG  city mpg   MSRP  \n",
       "0         Coupe           26        19  46135  \n",
       "1   Convertible           28        19  40650  \n",
       "2         Coupe           28        20  36350  \n",
       "3         Coupe           28        18  29450  \n",
       "4   Convertible           28        18  34500  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping only the neccessary columns\n",
    "df = df[['Make',\n",
    "'Model',\n",
    "'Year',\n",
    "'Engine HP',\n",
    "'Engine Cylinders',\n",
    "'Transmission Type',\n",
    "'Vehicle Style',\n",
    "'highway MPG',\n",
    "'city mpg',\n",
    "'MSRP']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the column names and replacing spaces with underscores\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make                  0\n",
       "model                 0\n",
       "year                  0\n",
       "engine_hp            69\n",
       "engine_cylinders     30\n",
       "transmission_type     0\n",
       "vehicle_style         0\n",
       "highway_mpg           0\n",
       "city_mpg              0\n",
       "msrp                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make                 0\n",
       "model                0\n",
       "year                 0\n",
       "engine_hp            0\n",
       "engine_cylinders     0\n",
       "transmission_type    0\n",
       "vehicle_style        0\n",
       "highway_mpg          0\n",
       "city_mpg             0\n",
       "msrp                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling the missing values with 0\n",
    "df = df.fillna(0)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the price binary (1 if above the average, 0 otherwise)\n",
    "dfp = df.copy()\n",
    "df['above_average'] = (df['msrp'] > df['msrp'].mean()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the 'msrp' (price) column\n",
    "del df['msrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7148, 2383, 2383)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into 3 parts: train/validation/test with 60%/20%/20% distribution.\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.above_average.values\n",
    "y_val = df_val.above_average.values\n",
    "y_test = df_test.above_average.values\n",
    "\n",
    "del df_train['above_average']\n",
    "del df_val['above_average']\n",
    "del df_test['above_average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: ROC AUC feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that  \n",
    "* For each numerical variable, use it as score and compute AUC with the above_average variable\n",
    "* Use the training dataset for that  \n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "(e.g. -df_train['engine_hp'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.  \n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "* engine_hp\n",
    "* engine_cylinders\n",
    "* highway_mpg\n",
    "* city_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>above_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  make       model  year  engine_hp  engine_cylinders transmission_type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  vehicle_style  highway_mpg  city_mpg  above_average  \n",
       "0         Coupe           26        19              1  \n",
       "1   Convertible           28        19              1  \n",
       "2         Coupe           28        20              0  \n",
       "3         Coupe           28        18              0  \n",
       "4   Convertible           28        18              0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7148 entries, 0 to 7147\n",
      "Data columns (total 9 columns):\n",
      "make                 7148 non-null object\n",
      "model                7148 non-null object\n",
      "year                 7148 non-null int64\n",
      "engine_hp            7148 non-null float64\n",
      "engine_cylinders     7148 non-null float64\n",
      "transmission_type    7148 non-null object\n",
      "vehicle_style        7148 non-null object\n",
      "highway_mpg          7148 non-null int64\n",
      "city_mpg             7148 non-null int64\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 502.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = list(df_train.dtypes[(df.dtypes == 'int64') | (df.dtypes == 'float64')].index)\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: engine_hp, ROC AUC: 0.9171031265539011\n",
      "Feature: engine_cylinders, ROC AUC: 0.766116490165669\n",
      "Feature: year, ROC AUC: 0.687551492804683\n",
      "Feature: city_mpg, ROC AUC: 0.6734244643245233\n",
      "Feature: highway_mpg, ROC AUC: 0.6330587871772013\n"
     ]
    }
   ],
   "source": [
    "feature_importance = {}  # Creating a dictionary to store feature importance scores\n",
    "\n",
    "for feature in df_train[numerical]:\n",
    "    # Calculating ROC AUC for each feature\n",
    "    auc_score = roc_auc_score(y_train, df_train[feature])\n",
    "        \n",
    "    if auc_score < 0.5:\n",
    "        # If AUC is less than 0.5, inverting the variable\n",
    "        inverted_feature = -df_train[feature]\n",
    "        auc_score = roc_auc_score(y_train, inverted_feature)\n",
    "        feature_importance[feature] = auc_score\n",
    "    else:\n",
    "        feature_importance[feature] = auc_score\n",
    "\n",
    "# Sorting features by ROC AUC score in descending order to get the most important features\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Printing the sorted feature importance\n",
    "for feature, auc_score in sorted_feature_importance:\n",
    "    print(f\"Feature: {feature}, ROC AUC: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: engine_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "* 0.678\n",
    "* 0.779\n",
    "* 0.878\n",
    "* 0.979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Applying one-hot encoding to the training data\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "# Training the logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the validation dataset: 0.980\n"
     ]
    }
   ],
   "source": [
    "# Applying one-hot encoding to the validation data\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "# Making predictions on the validation data\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculating the AUC score\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "# Printing the AUC rounded to 3 digits\n",
    "print(f\"AUC on the validation dataset: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute precision and recall for our model.\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "* 0.28\n",
    "* 0.48\n",
    "* 0.68\n",
    "* 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383130507763323"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valkm\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4FOe1+PHv2V31LiQESPTeDYjmKmzignvDvdvYcZxynfgmN3FsJ7GTXP+cm+LYsXEJ7rjbxMZxx+CYIgMG00wHFUAC9a7dfX9/zEosogmk1Ww5n+fZR9rZ2dmzo4WzZ+ad94gxBqWUUkqFPofdASillFKqc2hSV0oppcKEJnWllFIqTGhSV0oppcKEJnWllFIqTGhSV0oppcKEJnUV0URkrYjkHWWdPiJSIyLOLgrruIjIHBF50O44/InIAhG51ff7jSLypd0xteiq/SUieSJSeJzPPeI+89+/SoEmdRWkRGS7iNT7kukeEfmniCR29usYY0YaYxYcZZ2dxphEY4yns1+/q/iSg8e3P6tEZJWInGd3XIHi90Ws5WZEpNbv/il2x6hUIGhSV8HsfGNMIjAemAjc23YFsejnuH0W+/ZnKvA4MFdEUm2OKSD8vogl+t4zwFi/ZYuOZXsi4gpAmEp1Ov3PUAU9Y0wR8AEwCloPOT4kIv8B6oABIpIiIs+IyC4RKRKRB/0Pl4vIbSKyXkSqRWSdiIz3Ld8uItN9v08Ska99leweEfk/3/J+vkrP5bvfS0TmiUiZiGwWkdv8XucBEXlNRJ73vdZaEck93HsTkb+KSIHvNZf7V5BH25aIjBORFb7HXgVi27k/vcALQAIw2G97U0TkKxGp8FXyeX6PpfuOlhSLSLmIvONbniYi74lIqW/5eyKS05442uyHf4vIXW2WrRKRS3xf3P4sIiUiUikiq0Vk1LG+xmGkicj7vn24VEQG+r2+EZEfiMgmYJNv2TAR+dj3t/9ORGb6rT/D99mq9n0Gf9bm/fzU9x52ichNfstTfH/jUhHZISL3Hu6Lqoh8T0Q2+PbD3wHppP2gwoQmdRX0RKQ3MANY6bf4OmAWkATsAJ4D3MAgYBxwJtByLvdy4AHgeiAZuADYd4iX+ivwV2NMMjAQeO0wIb0CFAK9gMuA34vIGX6PXwDMxaqI5wF/P8LbywdOANKBl4HXRcQ/OR9yWyISDbyDlZzTgdeBS4/wOq18X3ZuApqx9h0ikg28Dzzo297PgDdFJNP3tBeAeGAk0B34s2+5A/gn0BfoA9Qf5f0ezsvAVX4xjvBt832sv+WpwBCs/XAFh/77HY+rgN8AacBm4KE2j18ETAZGiEgC8LEv1u6+5z4uIiN96z4D3G6MScL6AvqZ33Z6AClANnAL8JiIpPkee9T32ADgNKzP6U20ISIZwJtYR6wygC3AScf7xlWYMsboTW9BdwO2AzVABVbieRyI8z22APit37pZQGPL475lVwGf+37/EPjxEV5nuu/3hVj/wWe0WacfYAAX0BvwAEl+j/8BmOP7/QHgE7/HRgD1x/C+y7EOEx9xW1hJrhgQv8e/Ah48zHZvxPrSU4GVzOuBmX6P/xx4oc1zPgRuAHoCXiCtHfGfAJT73V8A3OoXw5eHeV4SUAv09d1/CHjW9/vpwEZgCuA4zs+TAQa1WTYHeNrv/gxgQ5vnnO53/wpgUZttPAnc7/t9J3A7kNxmnTzf/nb5LSvxvR+n77M7wu+x24EFbfcZVrJf4reeYH25vDXQ/x71Fjo3rdRVMLvIGJNqjOlrjLnTGFPv91iB3+99gShgl+/QcQXWf7bdfY/3xqpqjuYWrGpwg4jky6EHkvUCyowx1X7LdmBVYC12+/1eB8TKYc7J+g7JrvcdTq3Aqtgy2rGtXkCRMca/I9OOo7y/JcaYVKyqdB7gP1isL3B5y/7zxXIyVkLv7XvP5YeIP15EnvQdNq7C+mKUKsd4pYBvf74PXOlbdCXwku+xz7Cq/8eAPSIyW0SSj2X7R9B2/7YdjNn2cza5zT66BqsKB+tIyQxgh4h8ISJT/Z67zxjjPsRrZQDRHPi3a/t5atHLPx7f377gEOupCKZJXYUq/2RWgFXtZPi+BKQaY5KNMSP9Hh940BbabtCYTcaYq7C+DPwv8IbvkKu/YiBdRJL8lvUBio71DfjOn/8cmIlVBacClbTvPOkuIFtE/Nft057XNcbUAHcC14nION/iAqxKPdXvlmCM+aPvsXQ59KC6nwJDgcnGOm1xasvba08sbbwCXOVLhnHA534x/80YMwHr8P8Q4J7j2P7xaPs5+6LNPko0xnzfF2O+MeZCrM/POxz+9I2/vVhHTvr6LTvc52kX1hcswBok6n9fKdCkrsKAMWYX8BHwJxFJFhGHiAwUkdN8qzwN/ExEJvgGXQ0Skb5ttyMi14pIprEGklX4Fh9wGZsxpgDrMPcfRCRWRMZgVfgvHUfoSViHxEsBl4jch3XOvz0W+577IxFxicglwKT2vrAxZh/WfrnPt+hF4HwROUtEnL73liciOb79+wHW+eM0EYkSkZbknYR1aLlCRNKB+9sbwyHMx0puvwVe9f0dEJGJIjJZRKKwDtE30Obv0kXeA4aIyHW+fRDli224iESLyDUikmKMaQaq2hOjsS6TfA14SESSfJ/Lu7H+Hm29D4wUa/CgC/gR+48SKAVoUlfh43qsw5jrsM5Lv4F16BhjzOtY52hfBqqxqqj0Q2zjbGCtiNRgDZq70hjTcIj1rsI6z14MvI11TvXj44j5Q6xkuRHrkGsD7TycaoxpAi7BOudajnW+961jfP2/ADNEZIzvy8qFwC+xvmQUYFXDLf9HXIdVUW7AOh/8E79txGFVnEuAfx9jDK2MMY2+9zAd62/VIhl4Cut97sAaJPcIgIj8UkQ+ON7XPMb4qrEG7V2J9bffjXVEJ8a3ynXAdt9piDuAa9u56R9ifVnZCnyJ9d6fPcTr7wUuB/6ItQ8GA/85zrejwpQceEpOKaWUUqFKK3WllFIqTGhSV0oppcKEJnWllFIqTGhSV0oppcKEJnWllFIqTIRc56GMjAzTr1+/TttebW0tCQlt5xdRx0r3Y8fpPuw43Ycdp/uw4zp7Hy5fvnyvMSbz6GuGYFLv168fX3/9dadtb8GCBeTl5XXa9iKV7seO033YcboPO073Ycd19j4UkaNNAd1KD78rpZRSYUKTulJKKRUmNKkrpZRSYUKTulJKKRUmNKkrpZRSYUKTulJKKRUmNKkrpZRSYUKTulJKKRUmNKkrpZRSYSJgSV1EnhWREhFZc5jHRUT+JiKbRWS1iIwPVCxKKaVUJAhkpT4HOPsIj58DDPbdZgH/CGAsSimlVNgL2NzvxpiFItLvCKtcCDxvjDHAEhFJFZGexphdgYrpIFXFpJWthIZxEJvSZS+rlFIq9Bhj2Lq3lp1ldQcsH5iRSJ9u8TZFdSCxcmqANm4l9feMMaMO8dh7wB+NMV/67n8K/NwYc1C3FhGZhVXNk5WVNWHu3LmdEl+vovkM2fQkBqEuvjeVKUOpThpCQ2x3GmIzaIzJwOuM7ZTXCnc1NTUkJibaHUZI033YcboPOy6c92Flo2FHlYdGD7gc4BRwiuAQWm8COB3gcggusdbbVetlVamH1aUeSusPzpm9EoXfn7w/qXf2Ppw2bdpyY0xue9a1s0ubHGLZIb9hGGNmA7MBcnNzTad1v2mcwKr3ezG2WxMJBctIKMyHXR8fuE5MMjicflE7IDELkrMhuRck9QRX9BFeRCAnF/qedOB2wox2duo43Ycdp/uw48JhHxpjKK5sYG1RJet2VbGmqJJviyrZU9V43NuMjXJw0sBM8oZ1Z0TPZBy+DPbY55tZW1x1wD6zcx/amdQLgd5+93OA4i6NICaJ8vQT4LQ8677XCxU7oKoIKousnzV7wHj3P8frhpoSqCyEXd9AbWn7XiuhO4y4AEZeDL3GQ3RwHKpRSik7GGPYXdXAlpJaNuyuYv2uajbsrmLb3lq8xvgqaMHhEJwO63enw1dZ+5Y5xffTIUQ5HTgdgghs31tLeV0zACIwMDOREwdmMLJXMqOyU0iNj8LtMTR5vLg9Bo/X4DXWzeO1bk1uL00eL01uL1nJsUzqn05s1MGFWWZSLG5vZVfvvsOyM6nPA+4SkbnAZKCyS8+nH4rDAen9rVt7edxgPId/3N0IWz6DtW/Dypcg/2lreVwaJOdY1X734dB7EuRMgsTMjr0HpZQKQrsrG/h0wx6WbC1jS0kN2/bWUt+8///O7kkxDOuZzKT+6UQ5HXi9Bo8xrT89Xg6xbP/N7bt5vF7OGtmDkb2SGdErheE9k4iPDlyqczqsuIJFwN6piLwC5AEZIlII3A9EARhjngDmAzOAzUAdcFOgYgkop4sj7kZXDIy8yLo11lgJft8m35GAYqvi3/IZ/Ocv1vpp/a1D+8civR9MvgN6jD7ed6GUUp2modnDzrI6du6rY01xJZ+uL+HbIqua7ZkSy5CsJCYPSGdAZiIDMhIY1iOJbokxNkd9fFwOB+5ISOrGmKuO8rgBfhCo1w9KMYnWIfi2muuh+BsoXAaF+VBXfgwbNbDmbVj5IvQ/DabeBYOmW0cdlFKqE7Qk6R376tixr5aCsjp2lNWxs6yOstoma1CZw4HLKTS6vZRW7z93LQLjeqdyz1lDmT48iyFZiYgcakhVaHKIREalro5BVBz0nWrdjkd9OSx/DpY+CS9fDhlDYeqdMOYKa9tKKXUMiirqWfBdCZ9vKGVNUSW7qxoOeDwpxkWfbvFWhZ0Qg8cY3B4vbq8hyuGgd3ocvdPj6ZMez4CMRFLio2x6J4HnckpkVOqqC8Wlwck/gak/gLXvwOJH4V8/hk9/BxNvhXHXWOfvtXpXSh1GSVUDrywr4PUldRT++zMAslPjOHFQN/p1S6BvNytJ9+2WQFp8VFhV2x3hEMETwEvDj5Um9XDijIIxl8Poy2D7l7D4Mfjij9bNEQXJPa3kntYPciZYA/O6j/CNC1BKRRpjDF/vKOe5r7bz7zW7cXsNw9Id/GrGMKYNy2RgZngdKg8El0PwaKWuAkoE+p9i3fZugq0L/C7TK4bNH8Oql611oxKskfcjLoDhF0BChq2hK6WOX02jm9pGNzEuBzEuJ9Eu6zKvFsYYtu+rI397Gfnbyli2vYwd++pIjnVx44n9uHZKX7avySfv1AE2vovQ4vAldWNMUHwB0qQe7jIGWzd/xljX4xcss25bP4f3/gve/yn0P9VK7n1PtM7N6yF7pYKeMYZXlhXw4PvrqGs6+BJb8c2UJrK/qkyNjyK3bzp3nDaQC0/o1XrZ1/YujDscuHxfmrzGmqHObprUI5GIdQg+rR+MmWkl+T1rrPPxa9+G9++21otJ2X+YvvdEyM6FuFQ7I1dKtVFS3cAv3vyWzzaUcNKgbswY3ZMmt5dGt5eGZg9er8Fg/TM3GHqlxjGpXzoDMxNxOIIgC4W4liMhHq854KiIXTSpKyvJ9xht3U6/F/ZtsS6vK/BdYrfwYd+segKZw6DXOIjymxNfHPQtrYOVhfunz3X6jXZ1uCClt/U6SqlOUVLdwMKNe3nIV53ff/4IbpjaTxN1F/NP6sFAk7o6kAhkDLJuJ1xtLWuogqLlVoJvOVzvde9/jtdN//py2P7y4bfbezKc+ZBV8SuljqrZ42V3ZQMl1Q2UVjdSWt3I7qoGNuyqZk3x/nnMR2en8OcrxjKoe5LNEUcmp69YCZYR8JrU1dHFJsPAadbtMBZ++hGnjhtsDcir3n1g0q8thf/8DZ6ZDiMvgekPQFrfgIetVFeqqGti3qpiiisaKKlqYE91A2W1zb6OXw6inNb85FFOB9Eu383pOOAAlsdr2FXZQFF5Pbsq62lb/DkEBnVP5KSBGYzMTmFUr2Qm9E3D5dSxL3ZprdQ9mtRVGPE6o488b/6EG63E/tWjsOE9SOqx/zFxwAnXwik/1YF5KiSVVDVwzdNL2VRSQ5RT6J4US1ZyDNmpcXiNodnXOKTJ7aW20U2jX7MQfw4ReiTHMrl/OjlpcWSnxZGVHEtmUgyZSTF0S4gJivO2ar/WpK6VuoooMUlw+q+s5L7kcajbt/+x6t3w+YPWefxLZluT6SgVIooq6rnmqSWUVDfy4i2TOXFgNz2vHUFakrrb6z3Kml1Dk7rqWinZcNZDBy4zBr5+Bj74BczOg5kvQM8xtoSn1LHYvreWa55eSlVDMy/cMpkJffULaaRpSepBktM1qasgIGJNZ9tjLLx2PTzzPRiQh3VlrU9sijWqPiXbGmGfMQTSB+iIetXljDEUlteTv72MP36wAbfX8MptUxiVnWJ3aMoGWqkrdTi9J8LtC+GDe6zL6lr5rqOvKj6wd318hq8P/UTrZ6/xEB3f5WGr0FBcUc+G3VXsrWmirLaJfTWNlNU2U15n3S+va6LJ7SUuyklctJOEaBdx0U7iopzER1vLqhrcfL29jF2VVoOT7NQ4Xrx1IkOydOR5pGod/a6XtCl1CImZcPmcQz/m9UBNidWDfs+3UJBvnYf/br71uMMFWaOsBJ8+gAMq/bg0yMnV6j7CGGP4z+Z9PLd4O5+u33PAaPLYKAfdEmJIS4giLT6aPunxRLsc1Dd7qG+ybhX1zeyqrKfOdz/a5WB83zQm9UtnYr90hvZI0oFrEc7l1KSu1PFxOH1NaXpaVX3uzdby2n1Q9DUULLWuo1/5EjTXHnobB1X34yA6oevegwo4Ywxb99by2foS5ubvZEtpLekJ0Xw/byBnDM8iMzGGbonRrdOiKtURDq3UlepkCd1gyFnWDcDjhsaqA9ep3rV/hryCpfure3FCj1FWtzpx7l8/Ot46nN9S9Wt1H9RqG90s3baPl9Y18utln1NQVg/A2JwU/m/mWGaM7klslPMoW1Hq2Ln0kjalAszpgvj0A5fFp0PWSMi9ybpfV7Y/wRcsg22LDly/oQKWzfY9t5uV4FP7+Abr5UBilnXkoIU4rWvvk3rqef3jUN/k4a2VhdQ2ulsnanE5Hbgc1oQtLqfgclgdx5wOWrthfVtYyZeb9rJiZzluryHaCacOSWfWqQPJG5JJ73T9W6jAarl80a2Tzyhlo/j0A6v7trweKP3OSvqF+bBrtTVVbn3Z0bcdl2b1rfcfrZ/aB/qfBklZnfs+wsAn6/Zw/7y1FFXUH/NzRWBUrxRuPWUApwzOoHbHt5x5hk5FrLrO/i5tmtSVCl4OJ2SNsG4t1T1AU511KL9mj6/JjY+n2ZpEp6rowN71hfl+XwQE+p0MIy60bondu/QtBZuiinoemLeWj9ftYXD3RF65bQqjc1Jwe7w0ewxurzULW7PHi9tr/fR6rf88PcbqX90/I5H0hOjWbS4o1NMkqmu1Vup6Tl2pEBQdD90GWrf2aqqDfZthw/tWa9v5P7NuiVlWFZ+SDck5dKtNg+YpB3bACxNltU0s3rKP7/ZUs6Wkhs0lNWzdW4PL4eDnZw/jlpP7E+3SKYJV6Gmt1DWpKxUhouOtGfJ6joG8X0DJemugXvk2q6Iv3QibP2V0cx1sfBSGzYARFx3c9CZ9AETF2fMejpExhg27q/lsQwmfrt/DyoIKjLEakvROj2dQZiKnD+/ONZP7kJOm571V6Gq5Tl0rdaUikcj+w/r+PM2sevdRxjq3wPr3YPWrBz83KgGGng0jL4ZB04MywVfUNfH2yiJezS9gw+5qwBqB/uMzBpM3tDvDeiTpKHQVVpxaqSulDuKMojx9POTdDef9BXZ8ZY3Ab+Fphu1fwvp5sOZNiE6EtH4HbiMm2Xcov5c1UC9jMGRPsFrndiJjDJ+sL+GjtbtxiBDlskaol1Y38tG6PTS5vYzNSeHBi0Zx5sgsuieF3+kEpVo49Zy6UuqInFEw4LSDl4++DGY8AtsXWcm9pmT/Y8ZYXwIK860Bep4m3wNiXYPfe6I1215Kju88fo41Sv8Yrr83xrBgYyl//ngjqwsrSYuPIsblpNljtRGNcTm4cmJvrpzYhxG9OveLhFLBSluvKqWOn9MFA6dZt8PxeqFuL+z+1nct/jJY8zYsn3Pgeq44X1Xvu/Y+cygMv+CAQYDGGDaX1LBsexlvLi9kxc4KctLiePiyMVwyLhuXUwe3qcjWmtT1OnWlVEA4HNblcoPOsG5gJfraEt+ldi2X3RVaVX1VkTX5zqpX4JMH8GSNZm3q6bxSN5EPi2Mpq7Wq/py0OH5/8Wgum5CjI9WV8tFKXSnV9RwO34x3PYAJBz1c1+Qmf9W3lC59lYG7P2Hcnr8yAgfnpV3A3tPvZuzQQfTtFt86k5tSytKa1PWculKqq7g9XvbWNLGvtpF9vtajO8vqWL+rivW7qthRVocx0C3hDM6fcB3Rgwwjts3hpK+fhS8+BfNTmPz9sLyGXqmOcGlSV0oFitdrKCivY8PuajburmZjSQ2b9lSzdW8tTW7vAeuKQN/0eIb3TObicTmM65PKiQO77T9PPuIRmDQLPr4PPnkAvvh/4IrZv4GoOKvLXe9JkDMJep0QlJfZKRVI2qVNKXXMmtxevMYQ43K0HgKvb/KwfncV64qrWFtcxYbdVXy3u5q6Jk/r83LS4hjcPZHTfM1NMhKj6ZYYQ3pCND2SY0mIOcp/AZlD4Oq5sPULa0Y8/6lxGyqg8GvY8J513xEFPUb7tbadbA3A00P2Koy5HNaXYE3qSqmDeL2G4sp6tu2tZcOuatbtspL25tIaPF6DQyAuyklslJPyuiZa/h9JiYtieM8kZub2ZliPJIb2SGJIVtLRk3Z7DTjt0JfZAdSU7u94V5gPy5+DpU9YjyX13N+7vs9U67p5TfIqjPhyuiZ1pRQ0NHv4bEMJ87/dxYqtdez95N8HHCbvmRLLiJ7JfG9EFnHRThqaPdQ1eahv9pCRGMPIXsmM7JVMdmqcfYPYEjOtqW2HzbDue5phzxooyIfCZVayXz/PeqzPiXDWQ5A93p5YlepkrZW6jn5XKjJ5vYbFW/fx9soiPlyzm+pGN5lJMeTEOzh/fF/6ZSTQr1sCQ3skHdCBLGQ4o6xz7b3GweRZ1rLqPVZiX/BHeGoajJ4JZ9wHqb3tjVWpDmqp1HVGOaUiTHltE28sL+SlpTvYvq+OxBgXZ4/qwUUnZDN1YDcWLfyCvLzhdocZGElZMOk2GHMFfPlnWPwYrHsXxl0DU+60prRVKgS1VOo697tSYcwYQ0l1I5v21LCppJpvCir4YM1umtxeJvZL47++N4SzRvaIvOYmsckw/X7IvRkWPgwrX4Kvn4Uh58DUH0Dfk/aXPkqFAO3SplSY+9eqYh6Yt5Z9tU2ty9Lio5iZm8O1U/oyrIfOi05qb7jgUTj915D/DOQ/Bc99ADEpkDPBukSu90TIzoW4VLujVeqwnE7t0qZUWGr2ePnD/A08+59tjOuTyo+nD2ZQ90QGd08iIzFaZ2M7lMTuMO1/4OSfwPp/Wd3pCpbBF/8LGEAgc5iV4HMmWYfpk7OtUfVO/e9L2U8rdaXCUElVAz94eQX528u58cR+/HLGcJ0f/VhExcGYmdYNoKEKipbvb0izbh6seH7/+uKAxB4w4QY49R5wRNhpDBU0Wvup6+h3pUJfTaObt1YU8uhnm6lpcPPXK0/gwhOy7Q4r9MUmH9iNzuuFsi1QvgOqfI1odq2CBX+wkv6lT0N8ur0xq4jU2k9du7QpFbp27qvjucXbeS2/gOpGNyf0TuV/Lx3D0B5JdocWnhwO69C7/yh5Y2DFczD/HnjyNLji+cM/X6kA8eV0vU5dqVDj8Rq+2FjCi0t28vl3JThFmDG6Jzee1I/xfdLsDi/yiMCEGyFrNLx2PTxzFr0G3ATmNJ21TnUZEcHpEDxe79FX7gKa1JU6ioKyOuatKublpTspqqgnMymGu6YN4prJfemRol3LbJczAW7/At66jSGbnoAXNlgj61P72B2ZihBWUrc7CosmdaXaMMawsqCCT9bt4dP1JXy3pxqAqQO68csZwzlzZBZRTh0EF1QSMuDat9j48i8Ysv0FeNw3He3467VqVwHnFK3UlQpKe2saufu1VSzcWIrTIUzsl8a95w7neyOy6Nstwe7w1JGIUJx9DkNmfB/evQv+9SP49nU480GrLaxSAeLSSl2p4LN4yz5+PHclFfXN3HvucC6f0JuU+Ci7w1LHKq0fXD8PVsyBzx6E2Xkw9io449eQ3Mvm4FQ4cug5daWCh8drePSzTfzt0030y0hgzk2TGNFLZ30LaQ6HNRXtqEth0Z9gyROw9m2rwczkOzS5q07lckjQjH7XE4Mqou3cV8dVs5fwl082cdEJ2fzrrpM1oYeT2BT43m/hrnwYfh589Sj8ZTS8NQt2rbY7OhUmrEo9OJK6VuoqIhljmJtfwO/eW4dThP+bOZZLxufYHZYKlLS+1gQ1p99rVe0rX4DVr8LA062k32O03RGqEObSpK5U13N7vOyqbKCoop7ZC7fy2YYSThrUjYcvG0t2apzd4amukNYPzvkj5P0Cls+x2sA+cYrVAnbavZDc0+4IVQhyiETG3O8icjbwV8AJPG2M+WObx/sAzwGpvnV+YYyZH8iYVOTweg1Ltu3j1fwC8reVsbuqgZZ/d7FRDh44fwTXT+2Hw6GXPEWcuFSricyEG2DhI7D0SVjzFpz0YzjxhxCtVzqo9nM5Jfy7tImIE3gM+B5QCOSLyDxjzDq/1e4FXjPG/ENERgDzgX6BiklFhj1VDby5opBX8wvYsa+O5FgX04Z1p096PNmpcWSnxTGsRzKZSTF2h6rsFpdmXc8+8Rb45AFrLvnlc6zD9GOv0kYxql2cEVKpTwI2G2O2AojIXOBCwD+pG6BlVFIKUBzAeFQYK69t4oM1u5m3qoil28owBqYMSOe/pg/h7FE9iI3S/5zVEaQPgJnPw84l8OGv4N0fwNIn4MyHYMBpdkengpzTIRHRpS0bKPC7XwhMbrPOA8BHIvJDIAGYHsB4VBgqKKvj4Q+/44Nvd+H2GgZkJvDjMwZz4QnZ9M/QQ6jqGPWZArd+AmvehE9+A89fAEPOtgbTZQ61OzoVpJwOCZoubWIC9O1CRC4HzjLG3Oq7fx0wyRjzQ7917vbF8CcRmQo8A4wyxnjbbGsWMAsgKyszoSApAAAgAElEQVRrwty5czstzpqaGhITEztte5Gqq/djvdvwry3NfLS9GYfAtN4uTsx20SfJgYTotKD6Wey4ztyHDk8T2UXv0XfH6zg9DRT3OosdfWfSFBPeLV71c3js7v+qnrQY4ScTrF4Qnb0Pp02bttwYk9uedQNZqRcCvf3u53Dw4fVbgLMBjDGLRSQWyABK/FcyxswGZgPk5uaavLy8TgtywYIFdOb2IlVX7cfS6kbmrSrmH19uZm9NM5eMz+a/zxoWFo1V9LPYcZ2/D8+E2vtgwR/I/vqfZBd/ADHJ1uQ1ydnQcwycek9YDazTz+GxS1nzJakJ0eTlTQLs3YeBTOr5wGAR6Q8UAVcCV7dZZydwBjBHRIYDsUBpAGNSIaim0c2Ha3bz7qpi/rN5Lx6vYVK/dJ65YThje6faHZ4KdwkZcO6fYNLt8N18qCqGqiKoLIQv/wIbP4IrXoBuA+2OVNnEGQnXqRtj3CJyF/Ah1uVqzxpj1orIb4GvjTHzgJ8CT4nIf2ENmrvRBOp8gApJa4oquXlOPiXVjeSkxXHHaQO4YGw2Q3sk2R2aijSZQ6ybv82fwJu3wuxpcMmTMPQce2JTtrK6tAVH6grodeq+a87nt1l2n9/v64CTAhmDCl2fbyjhBy+vIC0+mldnTWFS//SQPV+uwtSg6TDrC3jtenjlSjjpJ3DKTyFWpxqOJMFUqevc7yoovbR0B7c8l8+AzATevvNEJg/opgldBae0vnDzhzDuOvjPX+D/RliXxVUUHP25Kiy4nJrUlTqkRreHh95fx6/eXkPe0O68Omsq3ZNDfxCcCnNRsXDh3+G2z2Ho2bDkH/DXsfDaDbBhPrgb7Y5QBZBDgqdLm879roLGkq37+OXb37K1tJbrpvTl/vNH4HLq904VQrLHW41jpj9gTT278gVY9441Yn7oDBh1iXXIXmeqCyva0EUpP+W1Tfx+/npeX15I7/Q4nrt5EqcNybQ7LKWOX0oOnPk7OOM+2PaF1ct9/Xuwei6k9oUpd1pNZGJ0wGc4CKZz6prUVZfbua+O5TvLWFVQybdFlawpqsTjNXw/byA/On0wcdFaxagw4YyyKvNB0+HcP8PGD2Dx4/Dvn8Pnv4cTroakrP3riwMSulvXwafkWD+jtINgsNOkriJOeW0T760u5o0VRawqqACsTmmjeqVwzeS+zJyYw7AeOmJYhTFXNIy40LoVfg2L/w7LZoPxHP454oCJt8H0+8Nqgptwo0ldhS1jDMWVDWwrrWVnWR07y+rYtKeahZtKafYYhvVI4pczhnHK4EwGd0/Uc+YqMuXkwuVzwN10YFL3uqGmxJrYpqrIajCz7EnY9BFc9Dj0PdG2kNXhOR0OTeoqfGwtreHznc28PXclS7dafctbRDmF3mnxXDelH5dOyGZEz2S9NE2pFq7og5fFJO2fne6Eq2HMTKtr3D9nwOQ7rKpdD8kHFaego99VaKtpdDPvm2Lm5u9kdWElAJlJ+5jcP53J/dMZ1D2JPt3i6ZEci9OhSVyp49bvZLjjP1a/96X/gPoyuPhJ0C/HQcPpcARNlzZN6qrdPF7Dsm1lvLOyiH+tLqauycPQrCTuO28E8ZXbuGLGNK3ClQqEmEQ49xFIyIQFv4d+p8D46+yOSvk4HUREP3UVJr4pqGDeN8W8t7qYkupG4qKcnD+2J1dO6sO43qmICAsW7NCErlSgnfoz2PElzL/HOi/ffbjdESl8lbqeU1eh4KmFW3lo/nqinQ7yhmZy/thenDG8O/HR+tFRqss5nHDJ0/DEydZsdbM+11HxQcDpAK8mdRXsvtq8lz98sJ6zR/bg4cvHkBwbZXdISqmkLLj0KXj+Iqtiv+hxuyOKeC6t1FWwK6qo565XVjIwM5FHZo4lMUY/KkoFjQF5cOo9sPBhqNkDfaZC70nQa7x1/l11KYeIVuoqeDU0e/j+i8tpcnt54roJmtCVCkZ5vwB3PWz80OrrDiBOGHsVnPUQxKXaG18EcTlFK3UVvB6Yt5bVhZU8ed0EBmbqt36lgpLDCWc+aN3qyqxZ6jZ/AvlPw5bP4IJHYfB0u6OMCMHUpU2n81Ktymqb+Pkbq5mbX8APpg3krJE97A5JKdUe8ekw5EyY8TDc+gnEJsNLl8K7d0Hpd9BYY3eEYU27tKmg4vEaXl66g0c+2khto5tZpw7g7u8NtTsspdTxyB4Pty+EBX+E//zFav8KEJsCydkw6TbIvdneGMOMw5fUjTG2X9qrST2CldU28fmGEp75chvrdlVx4sBu/OaCkQzO0naQSoU0V4w1nezYq2DXN9Y88pVFULQc3rsbknrC0HPsjjJsuHyzZnqNNWWsrbHY+/Kqq1XWNfPa1wV8vH4PX28vw2sgJy2Ox64ez4zRPWz/lqmU6kSZQ6xbi+Z6ePZsePM26zB992H2xRZGWqbC9niN7dNia1KPIAVldVz/7DK27a1lWI8k7po2iOkjshidnaLJXKlIEBUHV74Ms/Ng7lVw22cQl2Z3VCHPP6nbTZN6hFhTVMlNc/Jpcnt5ddYUJg/oZndISik7pGTDFS/AnPPgjZvh6tfBqamgI5y+oigYRsDr6PcI8OWmvVw5ewlRDuHN70/VhK5UpOszBc79k3Xp2/v/BZ5muyMKaa2VehB0atOvZ2FsS2kN76ws4okvtjAwM5E5N02iR0qs3WEppYLBhBugYgcs+hOUboSZz0GSXsZ6PFqTehBU6prUw0x5bRNvLC/k3VVFrCmqQgSmD8/ikcvHkhKnc7crpfyccR90HwHzfghPngqXz7E7opDUktTdXq/NkWhSDys79tVy7TNLKSirZ2xOCveeO5zzx/YiK1mrc6XUYYy+DLJGwtxrYM559Ol3NbinWpfFqXZpSepBkNM1qYeLDburuO6ZZbg9Xt78/olM6KsjWpVS7dR9uNXGdd4PGbDuBfj7Qpj+AIy8GPTKmKMKpkpdB8qFgRU7y7niySU4BF67faomdKXUsYtNgZnPs2rMbyA6Ed64CZ4505pTXh1Ry+j3IMjpmtRD3cKNpVz79FJS46N4444TdTY4pVSHlKefAHcsshrCVOyAp6fDR/daE9eoQ3I5tVJXneCFxdu5aU4+fdLjef2OqfROj7c7JKVUOHA4Yfz18MPlkHsTfPUoPHEKFOTbHVlQcrRU6kEw+l2Teghye7zc9+4afv3uWk4bksnrd0yle5IOhlNKdbKYJDjvz3Dd274pZs+ET38XHMeZg4ir9Zy6JnV1jCrrmrlpTj7PL97BrFMH8NT1uSTF6qVqSqkAGng63LkYxl4Nix6Bt24Fd6PdUQUNh04Tq47H2uJKfvDSCooq6nn40jHMnNjb7pCUUpEiNhku/LvVIObj+6CmBK58yRpgF+FcQZTUtVIPAcYYXlm2k4sf/4r6Zg8v3zZFE7pSquuJwEk/hotnw87F8M8ZULXL7qhsF0yVuib1IFfb6Obu11bxP299y+T+6cz/0SlM7Jdud1hKqUg29gq45nUo3w5PTYPNn9gdka20UlftUl7bxOVPLObdb4q4+3tDmHPTJLol6ixPSqkgMPB0uOkDiEmGFy+1ppptqLI7Klu0dmnTpK4Op7KumWufWcrm0hqeuXEiPzpjcOusRUopFRR6joHbF8JJP4GVL8LjU2HL53ZH1eWCqZ+6JvUgVNXQzPXPLmXTnhqevG4C04Z2tzskpZQ6tKhY+N5v4OaPICrOqtq3fmF3VF0qmLq0aVIPMjWNbm58dhlri6t4/JrxmtCVUqGh90S47TPIGAyv3wBl2+yOqMs49Tp1dSg1jW5u+ucyVhVW8verxzF9RJbdISmlVPvFJsOVL4MxMPdqaKyxO6Iusb9LmyZ15VNZ38x1zyxlxc4K/nblOM4e1dPukJRS6th1GwiX/xNKN8Dbt0fE7HNaqasDVNQ1ce3TS1lTVMnj14zn3DGa0JVSIWzg6XDmg7DhPVj4sN3RBJxW6qrVvppGrpy9hO/2VPPkdRM4a2QPu0NSSqmOm3InjLkSFvwB9qy1O5qA0rnfFWCNcr/6qaVs31fLMzfkcvowPYeulAoTInD2HyA6Cb4I72pdu7Qpmj1efvDSCraU1vD09RM5ZXCm3SEppVTnik+HybfDundgzzq7owkYl8NKpW6PJvWIZIzh/nlrWbRpL7+/ZDQnD86wOySllAqMqT+A6MSwPrfuy+l6nXqkenrRNl5eupM78wYyM1cbsyilwlh8OkyaBWvfgZINdkcTEC2Vus4oF4E+XLub33+wnnNH9+RnZw61OxyllAq8qXdBdELYVuutlbom9cjybWElP5n7DWNzUvnTzLGt7fqUUiqsJXSDSbfBmreg9Du7o+l0WqlHoF2V9dzyXD7pCdE8dX0usVFOu0NSSqmuM/WHEBUfliPhW7q06SVtEaK20c0tc76mrsnDszdOJDNJ26cqpSJMa7X+Juz+1u5oOpXTGSGTz4jI2SLynYhsFpFfHGadmSKyTkTWisjLgYzHDh6v4cdzv2HD7ir+fvU4hvZIsjskpZSyx8k/sQbOzb/Hmh8+TEREpS4iTuAx4BxgBHCViIxos85g4H+Ak4wxI4GfBCoeu/xh/no+Wb+H+88fSZ52XFNKRbK4NJj+AOxcDKtfszuaTtM6TWwQfFEJZKU+CdhsjNlqjGkC5gIXtlnnNuAxY0w5gDGmJIDxdLm3VhTy9JfbuH5qX244sZ/d4SillP1OuBayJ8DHv4aGKruj6RStDV2CYPIZMQH6ZiEilwFnG2Nu9d2/DphsjLnLb513gI3ASYATeMAY8+9DbGsWMAsgKytrwty5czstzpqaGhITEzttey12VHl4cEkDA1Ic3DMxtnVu4HAVqP0YSXQfdpzuw47rin2YVLWJ8SvuoTDnfLYMuiWgr9UVjDHc9GEdFw6M4uLB0Z2+D6dNm7bcGJPbnnVdnfaqBztUFmv7DcIFDAbygBxgkYiMMsZUHPAkY2YDswFyc3NNXl5epwW5YMECOnN7YHVdu/fRL+mWGMuLd54cEQPjArEfI43uw47TfdhxXbMP80DW0HvFC/Q+/38ga8RRnxHsnB/PJ6dPH/Lyhtn6OQzk4fdCwH+6tByg+BDrvGuMaTbGbAO+w0ryIcvjNfxo7jeUVDXyj2vHR0RCV0qpY3bG/RCbbA2aczfZHU2HOR2CJwhaxwcyqecDg0Wkv4hEA1cC89qs8w4wDUBEMoAhwNYAxhRwf/54Iws3lvLABSMZ1yfN7nCUUio4xafD9N/Aji/hL6Nh0Z+grszuqI6bUwSP1/6sHrCkboxxA3cBHwLrgdeMMWtF5LcicoFvtQ+BfSKyDvgcuMcYsy9QMQXaR2t38/fPNzMzN4erJumc7kopdUQTboBr34Tuw+HT38KfR1qVe33F0Z8bZFxBUqkH8pw6xpj5wPw2y+7z+90Ad/tuIW1LaQ13v7aKMTkp/PbCUYiE98A4pZTqFIOmW7c9a2Hx4/D1s7DpY7jiRegxyu7o2s3hCPNKPZLUNrq544XlRLsc/OPaCToFrFJKHauskXDRY3DjfHA3wNPTYdWrdkfVbi6HaOvVcGCM4b/fWM2W0hoevWoc2alxdoeklFKhq89kmPUFZI+Ht2fB+z8LiYF0VqWuST3kPbVoK+9/u4v/PnsYJw3KsDscpZQKfUlZcP27VsvW/KdgzrlQ1fbiqeDi0qQe+raW1vDHDzZwzqge3H7qALvDUUqp8OGMgrMegsvnWOfbnzwVti2yO6rDcoiE99zvkeDV/AJEhN9cOFIHximlVCCMvBhu+wxiU+H5C+GrR4OyGYzLKeHfpS2cNXu8vLmikNOHdad7Uqzd4SilVPjqPsxK7MNmwEf3wrt3gafZ7qgO4NRKPbR9tqGEvTVNXJGr16MrpVTAxSbDzBfgtF/ANy/CK1dBU63dUbVyOiTsu7SFtdfyC+ieFEPe0Ey7Q1FKqcggAtP+B877C2z5FOacBzWldkcFWEk9GLq0aVI/DnuqGvj8uxIunZCDy6m7UCmlulTuTXDFS1CyHp49E8p32B2RVuqh7I3lhXgNzNRD70opZY9hM+CGedZ88S9cDLX2zjDudOg59ZBkjOH1rwuY1D+d/hkJdoejlFKRq/ckuPpVqCqCl2faeo7dqdeph6al28rYvq9OB8gppVQw6DMFLn0GilfAGzeDx21LGFaXthBK6iJysojc5Ps9U0T6By6s4PVafgFJMS5mjO5pdyhKKaUAhp8HMx6Bjf+G935iy3XswVKpt6tLm4jcD+QCQ4F/AlHAi8BJgQst+FQ1NDN/zS4uGZ9DXLQ2bVFKqaAx8Rao3gUL/x+kD4BTurb5p9MhNLlDp0vbxcAFQC2AMaYYSApUUMHq5aU7aWj2cvWkPnaHopRSqq1pv7JmoPvsQdixuEtf2hliXdqafL3PDYCIRNwIsYZmD08v2sYpgzMYlZ1idzhKKaXaEoHz/wapfazz6104Ij5YDr+3N6m/JiJPAqkichvwCfBU4MIKPq8vL2RvTSN35g2yOxSllFKHE5tsNYGp2wvv3AHerjkkHlJd2owxjwBvAG9inVe/zxjzaCADCyZuj5cnv9jCuD6pTBmQbnc4SimljqTXCXDW72HTR7C4a1KVI0hGvx91oJyIOIEPjTHTgY8DH1Lw+dfqYgrL63ngfO3GppRSIWHirbB9EXzyG+h7EuTkBvTlXM7gSOpHrdSNMR6gTkQi8kSy12t4/PMtDOuRxOnDutsdjlJKqfYQgQsehfhusOj/Av5yIVOp+zQA34rIx/hGwAMYY34UkKiCyMfr97CppIa/XnkCDodW6UopFTJiU2DMTFj6pDWdbHzgTp+6Qmz0+/vAr4GFwHK/W1gzxvD4gi30SY/nXJ1sRimlQs+YmeBthnXvBPRlHEHSpa1dlbox5jkRiQaG+BZ9Z4wJrg71AbB8RzmrCip46OJR2o1NKaVCUY8xkDEUVr8GuTcH7GVcodSlTUTygE3AY8DjwEYROTWAcQWFTzeU4HIIF4ztZXcoSimljoeIVa3vXBzQFq2h1qXtT8CZxpjTjDGnAmcBfw5cWMFh0aZSxvdJIyk2yu5QlFJKHa/Rl1s/v309YC/hdAjeEErqUcaY71ruGGM2Ys3/Hrb21jSypqiKU4dk2B2KUkqpjkjrC32mWofgA3SI3CmhVal/LSLPiEie7/YUYT5Q7stNewE4dUimzZEopZTqsDEzYe93sHt1QDbvdDhCqlL/PrAW+BHwY2AdcEegggoGCzeWkhYfxcheEXl5vlJKhZcRF4EjyqrWA8DpIKQqdRfwV2PMJcaYi4G/AWHbe9TrNSzctJeTB2fi1GvTlVIq9MWnw+Az4ds3wOvp9M07HY6Quk79UyDO734cVlOXsLRhdzV7axo5dbCeT1dKqbAxZibU7IZtCzt9004HQTGjXHuTeqwxpqblju/3+MCEZL+Fm0oBPZ+ulFJhZcjZEJMckEPwTocDj9dgbK7W25vUa0VkfMsdEckF6gMTkv0WbixlWI8kspJj7Q5FKaVUZ4mKhREXwPp/QVNdp27a6Wv2ZXex3t6k/hPgdRFZJCILgbnAXYELyz51TW6+3l6uVbpSSoWjMVdAUzVs/KBTN+tyWknd7kPwR0zqIjJRRHoYY/KBYcCrgBv4N7CtC+Lrcku27qPJ4+UUPZ+ulFLhp+/JkNSr0w/BOyQEkjrwJNDk+30q8EusqWLLgdkBjMs2CzfuJTbKwcR+gevmo5RSyiYOB4y+DDZ/ArX7Om2zLt+VUnaPgD9aUncaY8p8v18BzDbGvGmM+TUwKLCh2WPhplIm9+9GbFTYXrGnlFKRbcwV4HXD2rc6bZMtrbk9NndqO2pSF5GWTm5nAJ/5PdbeXuwho7C8jq2ltXo+XSmlwlmPUdB9RKfOBR8qlforwBci8i7WaPdFACIyCKgMcGxd7puCCgCmDNBD70opFdbGzISCpVDWOcPDWip1t9fbKds77jiO9KAx5iHgp8Ac4GSz/wI8B/DDwIbW9cpqreED3ZP0UjallAprndy5raVStzmnH/2SNmPMEmPM28aYWr9lG40xKwIbWtdrSeqp8WHdgE4ppVRKjjUSvpM6t7Vcpx7UlXqkqahrJinWRZRTd4tSSoW9MTNh3yYoXtnhTTlDpVKPJGW1TaQnRNsdhlJKqa4w4kJwRsOypzq8KWconFOPNOV1TaTGa1JXSqmIEJcKU74Pq16GFc93aFOtlXqQj36PKOV1TaTr+XSllIocp98HA6bBe3fDzqXHvZn9lbom9aBRXttMmlbqSikVOZwuuPyfkNobXr0WKouObzOO0JgmNqKU1zWRpufUlVIqssSlwZWvQHM9vHqN9fMYOUNk7veI0dDsoa7JQ5oefldKqcjTfRhc+hQUfwMf33fMT3eGQpe2SFJR1wyglbpSSkWqoefACdfAypegseaYnqqVepApr7MmntFz6kopFcHGXwfNtbD+X8f0NJeeUw8u5bWa1JVSKuL1ngzpA+Cbl47paY5ISOoicraIfCcim0XkF0dY7zIRMSKSG8h4jqS89fC7nlNXSqmIJQJjr4bti6BiZ7ufFipd2o6biDiBx4BzgBHAVSIy4hDrJQE/Ao7/AsFOUOY7/J6ulbpSSkW2sVdYP1fNbfdTHBFwnfokYLMxZqsxpgmYC1x4iPV+BzwMNAQwlqOqaG3mokldKaUiWmof6H8qfPNyu5u97O/SZm9SdwVw29lAgd/9QmCy/woiMg7obYx5T0R+drgNicgsYBZAVlYWCxYs6LQga2pqWLBgAas3NhLrhK++XNhp244kLftRHT/dhx2n+7DjdB9asmLGMbx8ISvf/QeVqQcdZD7IjioPAN+s/pahCQ227cNAJnU5xLLWrzAi4gD+DNx4tA0ZY2YDswFyc3NNXl5e50QILFiwgLy8PN7d8w0ZVWV05rYjSct+VMdP92HH6T7sON2HPk0T4ZFnGOdYD3l3HnX1Dbur4KtFjBgxkrh939m2DwN5+L0Q6O13Pwco9rufBIwCFojIdmAKMM+uwXLaoU0ppVSr6ASri9uat6Gp7qir7++nHr7n1POBwSLSX0SigSuBeS0PGmMqjTEZxph+xph+wBLgAmPM1wGM6bAqtEObUkopfydcDU3VsOH9o64a9l3ajDFu4C7gQ2A98JoxZq2I/FZELgjU6x6vMu3QppRSyl+fE61Bc8vnHHXV1i5tnvAdKIcxZj4wv82yQ06qa4zJC2QsR1NR26yVulJKqf0cDph0O3z0K9ixGPpOPeyqznC/Tj2UNLm9VDe69Zy6UkqpA+XeDAmZ8MUfj7iatl4NIhX1LVPE6uF3pZRSfqLj4aQfw9YFsPPwc6RpUg8i5bXaoU0ppdRh5N4M8RlHrNa1S1sQ0Q5tSimlDis6warWt3wGBcsOuYrLYaVTTepBQDu0KaWUOqKJt1jV+oJDV+u+nK5JPRhohzallFJHFJ0AJ/4QtnwKhQdPp9Jaqevod/vp4XellFJHNfFWiO8GCx856CEdKBdEymubiItyEhvltDsUpZRSwSomEUZdBtsWgtdzwEOa1INIWZ3O+66UUqodcnKhuRZK1h+w2JfTw3ru95BRUddMql6jrpRS6miyJ1g/i5YfsFhEcDrE9n7qmtTRDm1KKaXaKX0AxKZC0cGD5ZwO0Uo9GGiHNqWUUu0iYlXrRSsOesgpEr5d2kJJWa12aFNKKdVOOblQsg4aaw5Y7HKI7V3aIj6pe7yGqga3ThGrlFKqfbIngPHCrlUHLHY4tFK3nW/ad71GXSmlVPu0DpY78Ly6yyG4vV4bAtov4pN6TbP1rUordaWUUu2SkAGpfQ8aAe9wCB57c7om9eomX1LXc+pKKaXaKycXCg9M6i6H4NFK3V6tlboefldKKdVe2blQVQjVu1sXOUQrddvVNOnhd6WUUsfoEJPQuJxaqduupVJP10pdKaVUe/UcAw7XAR3bnCLYfEWbJvXqJohxOYiL1mYuSiml2ikqDrJGHlCpO/Wcuv1qm41OEauUUurYZedC8UrwJXIrqet16raqbjI6RaxSSqljlz0BGqtg3yZAk3pQqGk2pCfo5WxKKaWOUU6u9dN3Xl0bugSBGq3UlVJKHY9ugyEmuXVmOa3Ug0BNs9GR70oppY6dwwG9xrUOlnOKJnVbebyG2madTU4ppdRxSuvXOgGNVuo2q6pvxqATzyillDpO0YnQVAtoUrddWV0ToFPEKqWUOk7RCVZS93qtpK6tV+1T0ZLUtVJXSil1PKITAAPueq3U7Vbma6au59SVUkodl+gE62dTra9LmyZ125Tr4XellFIdEZ1o/Wyq9XVp06Rumyn9uzFrTAyZSTF2h6KUUioU+VfqTk3qturTLZ4Te7mIjdJmLkoppY6DX1LXSl0ppZQKZa2H32usc+o6+l0ppZQKUf6VukNw29xQXZO6Ukopdbyi462fvtHvXq3UlVJKqRDld/hdu7QppZRSoczv8LvTIXg1qSullFIhyhUHiJXURSt1pZRSKnQ5HK3zvzsdDq3UlVJKqZAWneA7p45W6koppVRI86vU9Tp1pZRSKpS1JnV0RjmllFIqpEUn+g6/O/B4DcbGal2TulJKKdURLZW6CAB21uqa1JVSSqmO8CV1l9NK6nYegdekrpRSSnVEdCI01+HwVep2Tv+uSV0ppZTqCN8lbS6HVupKKaVUaPMdfneEe1IXkbNF5DsR2SwivzjE43eLyDoRWS0in4pI30DGo5RSSnW66ATwNBGNGwjTpC4iTuAx4BxgBHCViIxos9pKINcYMwZ4A3g4UPEopZRSARFlNXWJNg0Atk5AE8hKfRKw2Riz1RjTBMwFLvRfwRjzuTGmznd3CZATwHiUUkqpzufr1BbrrQfAzknlApnUs4ECv/uFvmWHcwvwQQDjUUoppTqfL6lHe6wa1c7R764AblsOseyQb1VErgVygdMO8/gsYBZAVlYWCxYs6KQQodqgVp0AABIASURBVKamplO3F6l0P3ac7sOO033YcboPj123vdsYDezath7oQ01tnW37MJBJvRDo7Xc/Byhuu5KITIf/3969B0dVpnkc/z500ukmCZkVHFcJC8wOgggkoRJNRCUroHgLVa4sug4LFrXjynKZZXeVwqox4+rWqHhZFIthHI2MrqJu1S6wWFA4RlfKKOzKAHIzKmJgxkscsRkIufDuH30SO+HW0N3p9MnvU9XFOX3ePv30Q8LD+563z8s9wHjn3NETncg5txxYDlBaWuoqKyuTFmRtbS3JPF9vpTwmTjlMnHKYOOXwLHwSgO1w4aDz4EMIhfumLYepHH7fBAwzs6FmFgRuAVbFNjCzEuAXQJVz7osUxiIiIpIa7cPv3jV1X85+d861AnOAdcBO4GXn3Admdp+ZVXnNHgbygFfMbIuZrTrJ6URERHqmYB4A2cf8fU0d59xaYG2X534asz0xle8vIiKSch0T5dp76v78SpuIiIj/eUU9uzXaU/fl8LuIiEiv4BX1rGMq6iIiIpktkA2BHLJbfTxRTkREpNcI5pLVpp66iIhI5gvmkeVNlNN66iIiIpksmEug9Y+AeuoiIiKZLZhLoGP2u77SJiIikrmCuWTpK20iIiI+EMylT0v67yinoi4iIpIoXVMXERHxiZieuoq6iIhIJgvm0adFPXUREZHMF8ylT+thjGOa/S4iIpLRvPu/h2lWT11ERCSjeUU9lybNfhcREclowTwA+lqTeuoiIiIZLaanrqIuIiKSybyi3ldFXUREJMN5w++5dlTX1EVERDJaTE/d6SttIiIiGayjqKunLiIiktk0+11ERMQnNPtdRETEJ7JCgJHX56iKuoiISEYzg2Ce7ignIiLiC8Fc8kw9dRERkcwXzCXXmrRKm4iISMYL5pKrnrqIiIgPBPN0m1gRERFf6Bh+T18IKuoiIiLJEMylr0vv7Pes9L118rS0tNDQ0EBTU9MZv7agoICdO3emIKrMEQqFKCwsJDs7O92hiIhkrmAe4TQPv/uiqDc0NJCfn8+QIUMwszN6bSQSIT8/P0WR9XzOORobG2loaGDo0KHpDkdEJHMFc71r6pr9npCmpib69+9/xgVdwMzo37//WY1yiIhIjGButKeexq66L4o6oIKeAOVORCQJgrlk0Ya51rSF4Juinm6BQIDi4mJGjRrF1KlTOXz4cMLn3Lx5M/PmzTvp8QMHDnDzzTcn/D4iIpIE3kptOe5o2kJQUU+ScDjMli1b2L59O8FgkGXLlnU67pzj2LFjZ3TO0tJSlixZctLjF1xwAa+++upZxSsiIknmrdSWfSx9lzNV1FPgiiuuoL6+nr1793LRRRcxe/Zsxo4dy2effcb69eupqKhg7NixTJ06lUOHDgGwadMmLrvsMoqKirjkkkuIRCLU1tZyww03APDmm29SXFxMcXExJSUlRCIR9u7dy6hRo4DovILbb7+d0aNHU1JSwhtvvAFATU0NN910E5MnT2bYsGHcdddd6UmKiIjfeUU9x6WvqPti9nusn63+gB0Hvo27fVtbG4FA4JRtRl7Qj3tvvDiu87W2tvLaa68xefJkAHbv3s2zzz7LU089xVdffcX999/Phg0byM3N5cEHH+TRRx9l4cKFTJs2jZUrV1JWVsa3335LOBzudN7FixezdOlSxo0bx6FDhwiFQp2OL126FIBt27axa9curr76avbs2QPAli1beP/998nJyWH48OHMnTuXQYMGxfV5REQkTu1FPY09dd8V9XQ5cuQIxcXFQLSnPmvWLA4cOMDgwYMpLy8HoK6ujh07djBu3DgAmpubqaioYPfu3Zx//vmUlZUB0K9fv+POP27cOBYsWMBtt93GTTfdRGFhYafjb7/9NnPnzgVgxIgRDB48uKOoT5gwgYKCAgBGjhzJp59+qqIuIpJs7UWdI2kLwXdFPd4edbtkfU+9/Zp6V7m5uR3bzjkmTZrEiy++2KnN1q1bTzsDfeHChVx//fWsXbuW8vJyNmzY0Km37k7xvcicnJyO7UAgQGtr+mZmioj4llfUg7qm3juUl5ezceNG6uvrATh8+DB79uxhxIgRHDhwgE2bNgHR/2h0LbwfffQRo0eP5u6776a0tJRdu3Z1On7llVfywgsvALBnzx727dvH8OHDu+FTiYgI0DH7PZTGa+oq6t3o3HPPpaamhltvvZUxY8ZQXl7Orl27CAaDrFy5krlz51JUVMSkSZOOuxnM448/zqhRoygqKiIcDnPttdd2Oj579mza2toYPXo006ZNo6amplMPXUREUkwT5fyjfRZ7rCFDhrB9+/ZOz1111VUdPfJYZWVl1NXVdXqusrKSyspKAJ544olTnj8UClFTU3Ncm5kzZzJz5syO/TVr1pzuo4iIyNnwinpI31MXERHJcNleUUfD7yIiIpktkEWzBXVNXURExA+OWpiQS99X2lTURUREkuRonzAhdE1dREQk4zUHwoQ1/C4iIpL5mvuECWuiXOaLXXr1xhtv5Jtvvknq+WtqapgzZw4A1dXVLF68OKnnFxGRxDX36evfom5mk81st5nVm9nCExzPMbOV3vF3zWxIKuNJpdilV88555yOBVZERKT3aAmE/fk9dTMLAEuBa4GRwK1mNrJLs1nAH5xzPwQeAx5MVTzdqaKigv3793fsP/zww5SVlTFmzBjuvffejudXrFjBmDFjKCoqYvr06QCsXr2aSy+9lJKSEiZOnMjnn3/e7fGLiMjZaQ70pW8ae+qpvKPcJUC9c+5jADN7CZgC7IhpMwWo9rZfBZ40M3OnWp3kdF5bCL/fFnfzcFsrBE6Thj8dDdf+PK7ztbW18frrrzNr1iwA1q9fz4cffsh7772Hc46qqireeust+vfvzwMPPMDGjRsZMGAAX3/9NQCXX345dXV1mBlPP/00Dz30EI888kjcn0dERNKntU8orcPvqSzqA4HPYvYbgEtP1sY512pmB4H+wFexjczsx8CPAc477zxqa2s7naSgoIBIJAJATkszfdrOYBUyB62naX+spZmj3vlP5siRI4wZM4Z9+/ZRXFxMeXk5kUiENWvWsG7dOoqKioDo7WS3bdvG4cOHqaqqIicnh0gkQnZ2NpFIhN27d7No0SI+//xzmpubGTx4MJFIhKamJpqbm4lEIhw9erSjfbI0NTUdl9czcejQoYReL8phMiiHiVMOExOx79OSNZztacphKov6idYS7doDj6cNzrnlwHKA0tJS134/9HY7d+78bvnUqkfPKMh4l14NnuZ4OBxm69atHDx4kBtuuIEVK1Ywb948srOzWbRoEXfccUen9kuWLCEnJ+e49164cCELFiygqqqK2tpaqquryc/PJxQKEQwGyc/PJycn54SvTUQoFKKkpOSsX19bW0vXvxc5M8ph4pTDxCmHCaqsTGsOUzlRrgEYFLNfCBw4WRszywIKgK9TGFPKFRQUsGTJEhYvXkxLSwvXXHMNzzzzTMeCL/v37+eLL75gwoQJvPzyyzQ2NgJ0DL8fPHiQgQMHAvDcc8+l50OIiEhGSmVPfRMwzMyGAvuBW4C/7tJmFTADeAe4GfhNQtfTe4iSkhKKiop46aWXmD59Ojt37qSiogKAvLw8nn/+eS6++GLuuecexo8fTyAQoKSkhJqaGqqrq5k6dSoDBw6kvLycTz75JM2fRkREMkXKirp3jXwOsA4IAM845z4ws/uAzc65VcCvgF+bWT3RHvotqYon1bouvbp69eqO7fnz5zN//vzjXjNjxgxmzJjR6bkpU6YwZcqU49rGLqFaXV2deMAiIuI7KV1P3Tm3Fljb5bmfxmw3AVNTGYOIiEhvoTvKiYiI+ISKuoiIiE/4pqj7YH5d2ih3IiL+4IuiHgqFaGxsVHE6C845GhsbCYVC6Q5FREQSlNKJct2lsLCQhoYGvvzyyzN+bVNTU68vaKFQiMLCwnSHISIiCfJFUc/Ozmbo0KFn9dra2tqE7qQmIiLSU/hi+F1ERERU1EVERHxDRV1ERMQnLNNmjJvZl8CnSTzlALos9SpnRXlMnHKYOOUwccph4pKdw8HOuXPjaZhxRT3ZzGyzc6403XFkOuUxccph4pTDxCmHiUtnDjX8LiIi4hMq6iIiIj6hog7L0x2ATyiPiVMOE6ccJk45TFzactjrr6mLiIj4hXrqIiIiPtFrirqZTTaz3WZWb2YLT3A8x8xWesffNbMh3R9lzxZHDheY2Q4z22pmr5vZ4HTE2ZOdLocx7W42M2dmmoV8AvHk0cz+yvt5/MDM/r27Y+zp4vh9/jMze8PM3vd+p69LR5w9lZk9Y2ZfmNn2kxw3M1vi5XermY3tlsCcc75/AAHgI+AHQBD4LTCyS5vZwDJv+xZgZbrj7kmPOHP4F0Bfb/tO5fDMc+i1ywfeAuqA0nTH3dMecf4sDgPeB/7E2/9+uuPuSY84c7gcuNPbHgnsTXfcPekBXAmMBbaf5Ph1wGuAAeXAu90RV2/pqV8C1DvnPnbONQMvAVO6tJkCPOdtvwpMMDPrxhh7utPm0Dn3hnPusLdbB2jpt87i+TkE+BfgIaCpO4PLIPHk8W+Bpc65PwA4577o5hh7unhy6IB+3nYBcKAb4+vxnHNvAV+foskUYIWLqgO+Z2bnpzqu3lLUBwKfxew3eM+dsI1zrhU4CPTvlugyQzw5jDWL6P9S5TunzaGZlQCDnHNrujOwDBPPz+KFwIVmttHM6sxscrdFlxniyWE18CMzawDWAnO7JzTfONN/M5PCF0uvxuFEPe6u0/7jadObxZ0fM/sRUAqMT2lEmeeUOTSzPsBjwMzuCihDxfOzmEV0CL6S6IjR/5jZKOfcNymOLVPEk8NbgRrn3CNmVgH82svhsdSH5wtpqSm9pafeAAyK2S/k+KGkjjZmlkV0uOlUQyu9TTw5xMwmAvcAVc65o90UW6Y4XQ7zgVFArZntJXodbpUmyx0n3t/n/3LOtTjnPgF2Ey3yEhVPDmcBLwM4594BQkTvaS7xievfzGTrLUV9EzDMzIaaWZDoRLhVXdqsAmZ42zcDv3HebAcB4sihN3T8C6IFXdcwj3fKHDrnDjrnBjjnhjjnhhCdl1DlnNucnnB7rHh+n/+T6MRNzGwA0eH4j7s1yp4tnhzuAyYAmNlFRIv6l90aZWZbBfyNNwu+HDjonPtdqt+0Vwy/O+dazWwOsI7orM9nnHMfmNl9wGbn3CrgV0SHl+qJ9tBvSV/EPU+cOXwYyANe8eYY7nPOVaUt6B4mzhzKacSZx3XA1Wa2A2gD/tk515i+qHuWOHP4j8AvzewfiA4bz1RH5ztm9iLRyzsDvHkH9wLZAM65ZUTnIVwH1AOHgdu7JS79HYmIiPhDbxl+FxER8T0VdREREZ9QURcREfEJFXURERGfUFEXERHxCRV1ER8ws/5mtsV7/N7M9nvb33hf60r2+1Wa2RndytbMak90Ix0zm2lmTyYvOpHeS0VdxAecc43OuWLnXDGwDHjM2y4GTntbT+8uiiKS4VTURfwvYGa/9NYVX29mYejoOf+rmb0JzDezc83sP8xsk/cY57UbHzMK8L6Z5XvnzTOzV81sl5m90L6qoZlN8Npt89aczukakJndbmZ7vPce1015EPE9FXUR/xtGdBnSi4FvgL+MOfY959x459wjwL8R7eGXeW2e9tr8E/D3Xs//CuCI93wJ8BOia23/ABhnZiGgBpjmnBtN9K6Vd8YG4y0/+TOixXyS93oRSQIVdRH/+8Q5t8Xb/l9gSMyxlTHbE4EnzWwL0ftW9/N65RuBR81sHtH/BLR67d9zzjV4q3Zt8c473Hu/PV6b54Aru8RzKVDrnPvSW8t7JSKSFLqOJuJ/savltQHhmP0/xmz3ASqcc0fo7Odm9t9E72Nd563Ed6LzZnHi5SZPRPenFkkB9dRFpN16YE77jpkVe3/+uXNum3PuQWAzMOIU59gFDDGzH3r704E3u7R5F6j0ZuxnA1OT9QFEejsVdRFpNw8oNbOt3tfg/s57/idmtt3Mfkv0evprJzuBc66J6GpUr5jZNqIz75d1afM7oBp4B9gA/F+yP4hIb6VV2kRERHxCPXURERGfUFEXERHxCRV1ERERn1BRFxER8QkVdREREZ9QURcREfEJFXURERGfUFEXERHxif8HJlN4Nbsu39oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Creating an array of thresholds from 0.0 to 1.0 with a step of 0.01\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Initializing lists to store precision and recall values\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "\n",
    "# Calculating precision and recall for each threshold\n",
    "for threshold in thresholds:\n",
    "    # Applying the threshold to the predicted probabilities to make binary predictions\n",
    "    binary_predictions = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    # Calculating precision and recall\n",
    "    precision = precision_score(y_val, binary_predictions)\n",
    "    recall = recall_score(y_val, binary_predictions)\n",
    "\n",
    "    precision_values.append(precision)\n",
    "    recall_values.append(recall)\n",
    "\n",
    "# Creating a plot showing precision and recall across thresholds\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision_values, label='Precision')\n",
    "plt.plot(thresholds, recall_values, label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and Recall curves intersect at threshold: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valkm\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculating F1-score for each threshold\n",
    "f1_scores = [2 * (precision * recall) / (precision + recall) for precision, recall in zip(precision_values, recall_values)]\n",
    "\n",
    "# Finding the threshold with the maximum F1-score\n",
    "max_f1_score = max(f1_scores)\n",
    "optimal_threshold = thresholds[f1_scores.index(max_f1_score)]\n",
    "\n",
    "print(f\"Precision and Recall curves intersect at threshold: {optimal_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "* 0.12\n",
    "* 0.32\n",
    "* 0.52\n",
    "* 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold at which F1 is maximal: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valkm\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Creating an array of thresholds from 0.0 to 1.0 with an increment of 0.01\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Initializing a list to store F1 scores\n",
    "f1_scores = []\n",
    "\n",
    "# Calculating F1-score for each threshold\n",
    "for threshold in thresholds:\n",
    "    # Applying the threshold to the predicted probabilities to make binary predictions\n",
    "    binary_predictions = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    # Calculating the F1-score\n",
    "    f1 = f1_score(y_val, binary_predictions)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Finding the threshold at which F1 is maximal\n",
    "max_f1 = max(f1_scores)\n",
    "optimal_threshold = thresholds[f1_scores.index(max_f1)]\n",
    "\n",
    "print(f\"Threshold at which F1 is maximal: {optimal_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: 5-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "* Iterate over different folds of df_full_train\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard deviation of the scores across different folds?\n",
    "* 0.003\n",
    "* 0.030\n",
    "* 0.090\n",
    "* 0.140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KFold cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Initialize a list to store AUC scores\n",
    "auc_scores = []\n",
    "\n",
    "# Initialize the one-hot encoding transformation\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Iterate over different folds\n",
    "for train_index, val_index in kf.split(df_train_full):\n",
    "    # Split the data into train and validation sets\n",
    "    train_data, val_data = df_train_full.iloc[train_index], df_train_full.iloc[val_index]\n",
    "    \n",
    "    # Extract features and target variables\n",
    "    X_train = train_data.drop(columns=['above_average'])\n",
    "    y_train = train_data['above_average']\n",
    "    X_val = val_data.drop(columns=['above_average'])\n",
    "    y_val = val_data['above_average']\n",
    "    \n",
    "    # Apply the one-hot encoding transformation to both training and validation data\n",
    "    X_train_encoded = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "    X_val_encoded = dv.transform(X_val.to_dict(orient='records'))\n",
    "    \n",
    "    # Create and train the logistic regression model with the specified parameters\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict_proba(X_val_encoded)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score for this fold and store it\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Calculate the standard deviation of the AUC scores across the different folds\n",
    "std_dev = np.std(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dev.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: [0.01, 0.1, 0.5, 10]\n",
    "* Initialize KFold with the same parameters as previously\n",
    "* Use these parameters for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "* 0.01\n",
    "* 0.1\n",
    "* 0.5\n",
    "* 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7625, 7624]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-d5a87d77089b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Train the logistic regression model on the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Make predictions on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1288\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\retinanet\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7625, 7624]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Specify the values of C to be tested\n",
    "C_values = [0.01, 0.1, 0.5, 10]\n",
    "\n",
    "# Initialize a dictionary to store the results for each C value\n",
    "results = {}\n",
    "\n",
    "# Initialize StratifiedKFold with the same parameters as previously\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Iterate over different C values\n",
    "for C in C_values:\n",
    "    # Initialize a list to store AUC scores for each fold\n",
    "    auc_scores = []\n",
    "\n",
    "    # Create and train the logistic regression model with the specified C value\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "\n",
    "    # Iterate over different folds\n",
    "    for train_index, val_index in kf.split(df_train_full, df_train_full['above_average']):\n",
    "        # Split the data into train and validation sets\n",
    "        train_data, val_data = df_train_full.iloc[train_index], df_train_full.iloc[val_index]\n",
    "    \n",
    "        # Extract features and target variables\n",
    "        X_train = train_data.drop(columns=['above_average'])\n",
    "        y_train = train_data['above_average']\n",
    "        X_val = val_data.drop(columns=['above_average'])\n",
    "        y_val = val_data['above_average']\n",
    "    \n",
    "        # Apply one-hot encoding as needed\n",
    "    \n",
    "        # Train the logistic regression model on the training set\n",
    "        model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "        # Make predictions on the validation set\n",
    "        y_pred = model.predict_proba(X_val_encoded)[:, 1]\n",
    "    \n",
    "        # Calculate the AUC score for this fold and store it\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Calculate the mean and standard deviation of AUC scores for this C value\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    std_auc = np.std(auc_scores)\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    results[C] = (round(mean_auc, 3), round(std_auc, 3))\n",
    "\n",
    "# Print the results\n",
    "for C, (mean_auc, std_auc) in results.items():\n",
    "    print(f\"C = {C}: Mean AUC = {mean_auc}, Std = {std_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
